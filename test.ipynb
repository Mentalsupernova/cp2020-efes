{
  "metadata": {
    "name": "test",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nimport org.apache.spark.mllib.tree.GradientBoostedTrees\nimport org.apache.spark.mllib.tree.configuration.BoostingStrategy\nimport org.apache.spark.mllib.tree.model.GradientBoostedTreesModel\nimport org.apache.spark.mllib.util.MLUtils\nimport org.apache.spark.ml.feature.VectorAssembler\nimport org.apache.spark.ml.feature.StringIndexer\n"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nval prefix \u003d \"file:///mnt/data/s3/cp2020/\"\n\nval df_raw \u003d spark.read.format(\"csv\")\n   .option(\"sep\", \",\")\n   .option(\"inferSchema\", \"true\")\n   .option(\"header\", \"true\")\n   .load(prefix+\"big_train.csv\") \n   \n\nval target_raw \u003d spark.read.format(\"csv\")\n   .option(\"sep\", \",\")\n   .option(\"inferSchema\", \"true\")\n   .option(\"header\", \"true\")\n   .load(prefix+\"target.csv\")\n  \nz.printSchema(df_raw) //тут\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nval df \u003d df_raw.join(target_raw,df_raw(\"_c0\") \u003d\u003d\u003d target_raw(\"_c0\")).drop(\"_c0\")\ndf.write.parquet(\"dataDriver_Result.parquet\")\nz.show(df)"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nval cols \u003d Array(\"year\",\"oil\",\"mining\",\"oil_gas\",\"gas_natural\",\"materials\",\"meal\",\"meat\",\"meat_birds\",\"sausiges\",\"cans\",\"fish\",\"milk\",\"milk_prod\",\"chese\",\"flawor\",\"bread\",\"value_undefinded\",\"target\")\n\nval tmp \u003d new VectorAssembler()\n  .setInputCols(cols)\n  .setOutputCol(\"features\")\n\nval featureDf \u003d tmp.transform(df)\nfeatureDf.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nval indexer \u003d new StringIndexer()\n  .setInputCol(\"target\")\n  .setOutputCol(\"label\")\nval labelDf \u003d indexer.fit(featureDf).transform(featureDf)\nlabelDf.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n/*\nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.mllib.regression.LabeledPoint\nval features_raw \u003d  spark.read.format(\"csv\")\n      .option(\"inferSchema\", \"true\")\n      .option(\"header\", \"true\")\n      .option(\"delimiter\", \",\")\n      .option(\"encoding\", \"utf8\")\n      .load(\"file:///mnt/data/s3/cp2020/target.csv\")\n      .toDF(\n \"_c0\", \"features\"\n)\n//val df \u003d spark.read.options(Map(\"delimiter\"-\u003e\";\")).csv(fname)\nval df_raw \u003d spark.read.format(\"csv\")\n      .option(\"inferSchema\", \"true\")\n      .option(\"header\", \"true\")\n      .option(\"delimiter\", \",\")\n      .option(\"encoding\", \"utf8\")\n      .load(\"file:///mnt/data/s3/cp2020/sample_train.csv\")\n      \nval df \u003d df_raw.join(features_raw,df_raw(\"_c0\") \u003d\u003d\u003d  features_raw(\"_c0\"),\"inner\").drop(\"_c0\")\n\n      \nz.show(df.header)\n*/"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nval splits \u003d df.randomSplit(Array(0.7, 0.3))\nval (trainingData, testData) \u003d (splits(0), splits(1))"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n/*\n//constants\nval IT \u003d 100 \nval TSNC \u003d 67\nval TSMD \u003d 2\nval TSCFI \u003d Map[Int,Int]() // in case of need\nval ALGO \u003d \"Classification\" // формула биновинальной ошибки если не подойдет возьмем l1 и l2\n*/\n"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n/*\n//init GBT\nval BSGBT \u003d  BoostingStrategy.defaultParams(ALGO)\nBSGBT.numIterations \u003d IT\nBSGBT.treeStrategy.numClasses \u003d TSNC\nBSGBT.treeStrategy.maxDepth \u003d TSMD\nBSGBT.treeStrategy.categoricalFeaturesInfo \u003d TSCFI\n*/"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n/*\nval model \u003d GradientBoostedTrees.train(trainingData, BSGBT)\n*/"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nimport org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\nval seed \u003d 5043\nval Array(trainingData, testData) \u003d labelDf.randomSplit(Array(0.7, 0.3), seed)\n\n// train Random Forest model with training data set\nval randomForestClassifier \u003d new RandomForestClassifier()\n  .setImpurity(\"gini\")\n  .setMaxDepth(3)\n  .setNumTrees(1000)\n  .setFeatureSubsetStrategy(\"auto\")\n  .setSeed(seed)\nval randomForestModel \u003d randomForestClassifier.fit(trainingData)\n\n//println(randomForestModel.toDebugString)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\nval predictionDf \u003d randomForestModel.transform(testData)\nz.show(predictionDf)"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n"
    }
  ]
}